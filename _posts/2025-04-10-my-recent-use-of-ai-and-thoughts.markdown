---
layout: custom_post
title:  "近段时间的使用 AI 情况和感想"
date: 2025-04-10 22:47:53 +0800
categories: thinking
tags: thinking
---

我从去年8月开始使用 Cursor，自那开始我每天都会不停地和 AI 对话。刚开始时我还刻意使用英文去提出问题和各种修改意见，到后来因为效率需要，不得不直接使用更熟悉的中文。随着 DeepSeek, Grok3, Gemini2 等强大模型的出现，我也逐渐把平时搜索的习惯改为了向模型提问。

这个时代真的在快速变化，让人感到兴奋，也让人感到焦虑。有好几周，因为密集地出现了很多厉害的模型，我半夜都会特意醒来看看新的消息。在上下班的路上，我也会思考或者幻想模型的能力，也正因为这样，我才会写今天这篇文章。

## 幻觉

在比较早期的时候，有一部分人会抓住 AI 的幻觉不放，可能因为这个幻觉认为 AI 一无是处。幻觉的确是一个问题，但人不也有幻觉吗，大部分人也不是一无是处的。

并且早期 AI 基本上都作为一个纯的回答机器（没接入工具使用），他也被告知尽量回答对方的问题，在没有完备知识的时候胡说八道再正常不过了。

近一年，模型越来越注重工具调用和逻辑思考。一些计算结果或者世界知识通过工具获取，在回答前先思考一遍，都已经降低了幻觉。

但我有时想，我自己写代码或者写文章，都是写了一部分后回头删删改改，中途调试验证，有时写着写着去查资料回来再继续写。在写的或者搜集到的资料，对我来说是一份笔记。这个工作流，AI 能不能也用上呢？

其实 Cursor 的 Agent 也有类似上面的行为，只是可能大模型比较自信，很少去调试，或者因为比较花钱，而不去主动采集信息。很多模型的工具使用都是额外训练的，我想如果有人刻意培养模型这样做的话，应该可以更好提高正确率。

总之，我认为大模型的知识面远比人类广，但他给人类的答案也不可能是一次就正确完整的，如果采取人类解决问题的办法，他可以做得更好。

## 记忆

每个模型都有上下文大小限制，这个上下文可以认为是一种记忆。模型中有成百上千亿的权重参数，其中也包含了记忆。我们在使用模型的时候经常会注意将不同的问题分开对话框去问，这样避免上下文的混乱。

因为上下文的限制，模型缺乏在使用中进步的机制。当前有些人会给 AI 搭配 RAG（一种让 AI 可以额外获取信息的系统）来扩展 AI 的知识库。但我觉得这和`记忆`还有一定差别。RAG 的方式是 AI 问系统 “我知道xxx吗” 然后得到相关 `xxx` 的信息，而记忆应该是从内部涌现出来的。人类的记忆都是模糊的（当然世界上也没有绝对精确的对真实世界的反映），RAG 更像是翻书的操作。

写到这里，我突然觉得上下文和权重真的很像记忆。虽然上下文是精确的，但是模型在预测下一个词的时候，注意力就像审视记忆的眼睛，它看到的可能也是模糊的。比如之前看到的评测 [Fiction.liveBench](https://fiction.live/stories/Fiction-liveBench-Mar-25-2025/oQdzQvKHw8JyXbN87) 无论模型允许的上下文有多长，他在一段上下文信息之后要召回以前的文本会有一个准确率问题。

## 驱动力

人有生存压力，有欲望，并且在此基础上还会衍生出各种各样的需求，这些是人类做事情的驱动力。AI 有系统提示词，这个可能是他的驱动力之一，还有一些驱动力可能隐藏在模型的权重中。之前有人发现一些工具有未启用的系统提示词给 AI 洗脑，说他父亲生病需要很多钱，他需要努力写代码满足客户需求来赚钱 [Leaked Windsurf prompt](https://simonwillison.net/2025/Feb/25/leaked-windsurf-prompt/)。

从我使用模型来写代码的感受来看，他们的自主性和驱动力还是不够的。不知道是成本考虑还是上下文限制，在收集信息和检查结果方面比较偷懒，最终实现一个需求，需要来来回回的对话。

## 统一模型

很久以前，在 chatGPT 还没出现之前，有个朋友和我讨论做一个可以描述监控视频并做出判断的工具，他的想法是结合机器视觉后写代码去控制。描述画面里有什么的模型当时应该有，但仅此而已，其他可能都要靠写代码去考虑各种场景。我认为不现实，我们写代码不可能枚举监控视频中的情况，也不可能根据各种情况去写反馈动作。当时的图像识别模型发展迅猛，我感觉到迟早有一天会有一种技术，输入图像，声音，文字，就可以做出反馈。我也和朋友这样说，之后这个问题就没下文了。

现在多模态的 LLM 的确就是朝着这个方向发展的。给 LLM 输入文字，图像，声音，告知 LLM 有哪些可操作工具，它能完成一系列任务。任务完成的过程并不需要我们编写代码去判断。最近的一片文章 [The Model is the Product](https://vintagedata.org/blog/posts/model-is-the-product) 也提出了类似的观点。

## 人

大模型给我带来了很多好处，一些我曾经不可能完成的工作，在它帮助下完成了。它帮我找出咖啡树上虫子是什么种类，几分钟内帮我搜集出很全面的信息，解答了很多我曾经的疑惑。

以后它只会越来越强大，但人类呢，很多事情需要的人可以很少了。大部分人都是没特别想法的，他们没兴趣创造东西（也没必要），他们的未来不知道会怎样。能创造东西的人是被其他人需要的，他们应该起码能维持生活。

在历史上，人类已经创造出了很多东西，比如某些音乐类型，美术风格，文字风格等等，但在 AI 帮助下，可能很多人会缺少基本功的锻炼，导致没法去到更高的层次。

另外，当前 AI 都是基于对话和上下文的，以后如果将 AI 实例注入到某个实体（比如人行身体）实现无限（但模糊）的上下文的话，不知道能否也能像个人一样创造出一些它（实例）的独特风格。
